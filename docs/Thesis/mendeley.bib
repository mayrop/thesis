@book{Thompson2012,
author = {Thompson, Steven K.},
edition = {3rd},
isbn = {978-0-470-40231-3},
publisher = {Wiley},
title = {{Sampling}},
year = {2012}
}
@techreport{Meng2013,
abstract = {Analyzing data sets of billions of records has now become a regular task in many companies and institutions. In the statistical analysis of those massive data sets, sampling generally plays a very important role. In this work, we describe a scalable simple random sampling algorithm, named ScaSRS, which uses probabilistic thresholds to decide on the fly whether to accept, reject, or wait-list an item independently of others. We prove, with high probability, it succeeds and needs only O(√ k) storage, where k is the sample size. ScaSRS extends naturally to a scalable stratified sampling algorithm, which is favorable for heterogeneous data sets. The proposed algorithms , when implemented in MapReduce, can effectively reduce the size of intermediate output and greatly improve load balancing. Empirical evaluation on large-scale data sets clearly demonstrates their superiority.},
author = {Meng, Xiangrui},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Meng - 2013 - Scalable Simple Random Sampling and Stratified Sampling.pdf:pdf},
title = {{Scalable Simple Random Sampling and Stratified Sampling}},
year = {2013}
}
@techreport{Kohavi1995,
abstract = {We review accuracy estimation methods and compare the two most common methods: cross-validation and bootstrap. Recent experimental results on artiicial data and theoretical results in restricted settings have shown that for selecting a good classiier from a set of classi-ers (model selection), tenfold cross-validation may be better than the more expensive l e a ve-one-out cross-validation. We report on a large-scale experiment|over half a million runs of C4.5 and a Naive-Bayes algorithm|to estimate the eeects of diierent parameters on these algorithms on real-world datasets. For cross-validation, we v ary the number of folds and whether the folds are stratiied or nott for boot-strap, we v ary the number of bootstrap samples. Our results indicate that for real-word datasets similar to ours, the best method to use for model selection is tenfold stratiied cross validation, even if computation power allows using more folds.},
author = {Kohavi, Ron},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Kohavi - 1995 - A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection(2).pdf:pdf},
title = {{A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection}},
url = {http://robotics.stanford.edu/{~}ronnyk},
year = {1995}
}
@techreport{Breiman2001,
abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund {\&} R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, * * * , 148-156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
author = {Breiman, Leo},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Breiman - 2001 - Random Forests.pdf:pdf},
keywords = {classification,ensemble,regression},
pages = {5--32},
title = {{Random Forests}},
volume = {45},
year = {2001}
}
@article{Salazar2012,
abstract = {The classification of individuals is a common problem in applied statistics. If X is a data set corresponding to a sample from an specific population in which observations belong to g different categories, the goal of classification methods is to determine to which of them a new observation will belong to. When g = 2, logistic regression (LR) is one of the most widely used classification methods. More recently, Support Vector Machines (SVM) has become an important alternative. In this paper, the fundamentals of LR and SVM are described, and the question of which one is better to discriminate is addressed using statistical simulation. An application with real data from a microarray experiment is presented as illustration.},
author = {Salazar, Diego Alejandro and Salazar, Juan Carlos and V{\'{e}}lez, Jorge Iv{\'{a}}n},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Salazar, Salazar, V{\'{e}}lez - 2012 - Comparison between SVM and logistic regression Which one is better to discriminate.pdf:pdf},
issn = {0120-1751},
journal = {Revista Colombiana de Estadistica},
keywords = {Classification,Genetics,Logistic regression,Simulation,Support vector machines},
number = {2 SPEC. ISSUE},
pages = {223--237},
title = {{Comparison between SVM and logistic regression: Which one is better to discriminate?}},
volume = {35},
year = {2012}
}
@techreport{Belsley1984,
abstract = {Old saw: Collinearity will not harmforecasts as long as it continues into the forecast period. If, however, collinearity is unlikely to continue but has already harmed estimation, then corrective action (introduction of prior information) to improve estimates should improve forecasts. This paper marshals the diagnostic information needed to assess collinearity's continuance and, when required, to direct meaningful corrective action. The process is illustrated by an example involving forecasts using energy prices. KEY WORDS I11 conditioning Regression diagnostics Corrective action Inventory investment Improving forecasts Multicollinearity It is well known that collinearity need not harm forecasts, even if it has harmed structural estimation, as long as it continues into the forecast period. If, however, it is determined that collinearity exists which is unlikely to continue into the forecast period and which has harmed structural estimates over the estimation period (e.g. produced unreasonable coefficients or incorrect signs), then some means to improve structural estimates in line with prior information will probably result in more meaningful forecasts. Model builders have often attempted to deal with this issue somewhat informally by dropping variates thought to be collinear, or by replacing subsets of the collinear variates by specific linear combinations (such as principal components). Such restrictions often violate a przori considerations (for example, that the dropped variates really do belong in the model), thereby leading to specification errors with their consequent estimation biases. These estimation biases become forecasting biases when projecting into situations where the collinearity no longer prevails. In this paper we examine a more correct procedure for dealing with collinearity under these circumstances, a procedure based on diagnostic information that has only recently become available. The collinearity diagnostics of Belsley, Kuh and Welsch (1980) and Belsley (1982) are first summarized. Taken together these diagnostics allow the forecaster to determine the presence and the structure of harmful collinearity over the estimation period. This information helps to assess whether the collinearity is likely to continue into the prediction period and, if not, where prior information can most meaningfully be employed to produce structural estimates from which more useful forecasts can result.},
author = {Belsley, David A},
booktitle = {Journal of Forecasting},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Belsley - 1984 - Collinearity and Forecasting.pdf:pdf},
pages = {183--196},
title = {{Collinearity and Forecasting}},
volume = {3},
year = {1984}
}
@techreport{Harrell,
abstract = {Logistic multiple regression using the method of maximum likelihood is now the method of choice for many regression-type problems involving binary, ordinal. or nominal dependent variables. Logistic regression does not require grouping of observations to obtain valid estimates of effects and of outcome probabilities, and it has been shown in the binary case to provide more accurate probability estimates than linear discriminant analysis when the assumptions of the latter (i.e., multivariate normality of predictor variables with common covariance matrix) are violated. Even when multivariate normality holds, logistic regression has been shown to yield probability estimates virtually as accurate as those obtained using discriminant analysis. The assumptions of the logistic regression model are for the most part straightforward and easy to verify. A general purpose SAS macro language program to verify the assumptions of the binary or ordinal model graphically will be discussed. Examples demonstrating the advantages of logistic regression for binary and ordinal dependent variables over other methods will also be presented. Background},
author = {Harrell, Frank E and {Kerry Lee}, Jr L},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Harrell, Kerry Lee - Unknown - THE PRACTICAL VALUE OF LOGISTIC REGRESSION.pdf:pdf},
title = {{THE PRACTICAL VALUE OF LOGISTIC REGRESSION}}
}
@techreport{Hothorn,
abstract = {The assessment of the performance of learners by means of benchmark experiments is an established exercise. In practice, benchmark studies are a tool to compare the performance of several competing algorithms for a certain learning problem. Cross-validation or resampling techniques are commonly used to derive point estimates of the performances which are compared to identify algorithms with good properties. For several benchmarking problems, test procedures taking the variability of those point estimates into account have been suggested. Most of the recently proposed inference procedures are based on special variance estimators for the cross-validated performance. We introduce a theoretical framework for inference problems in benchmark experiments and show that standard statistical test procedures can be used to test for differences in the performances. The theory is based on well defined distributions of performance measures which can be compared with established tests. To demonstrate the usefulness in practice, the theoretical results are applied to regression and classification benchmark studies based on artificial and real world data.},
author = {Hothorn, Torsten and Leisch, Friedrich and Zeileis, Achim and Hornik, Kurt},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Hothorn et al. - Unknown - The Design and Analysis of Benchmark Experiments Torsten Hothorn.pdf:pdf},
keywords = {bootstrap,cross-validation,hypothesis testing,model comparison,performance},
title = {{The Design and Analysis of Benchmark Experiments Torsten Hothorn}}
}
@techreport{Belsley1984a,
abstract = {Old saw: Collinearity will not harmforecasts as long as it continues into the forecast period. If, however, collinearity is unlikely to continue but has already harmed estimation, then corrective action (introduction of prior information) to improve estimates should improve forecasts. This paper marshals the diagnostic information needed to assess collinearity's continuance and, when required, to direct meaningful corrective action. The process is illustrated by an example involving forecasts using energy prices. KEY WORDS I11 conditioning Regression diagnostics Corrective action Inventory investment Improving forecasts Multicollinearity It is well known that collinearity need not harm forecasts, even if it has harmed structural estimation, as long as it continues into the forecast period. If, however, it is determined that collinearity exists which is unlikely to continue into the forecast period and which has harmed structural estimates over the estimation period (e.g. produced unreasonable coefficients or incorrect signs), then some means to improve structural estimates in line with prior information will probably result in more meaningful forecasts. Model builders have often attempted to deal with this issue somewhat informally by dropping variates thought to be collinear, or by replacing subsets of the collinear variates by specific linear combinations (such as principal components). Such restrictions often violate a przori considerations (for example, that the dropped variates really do belong in the model), thereby leading to specification errors with their consequent estimation biases. These estimation biases become forecasting biases when projecting into situations where the collinearity no longer prevails. In this paper we examine a more correct procedure for dealing with collinearity under these circumstances, a procedure based on diagnostic information that has only recently become available. The collinearity diagnostics of Belsley, Kuh and Welsch (1980) and Belsley (1982) are first summarized. Taken together these diagnostics allow the forecaster to determine the presence and the structure of harmful collinearity over the estimation period. This information helps to assess whether the collinearity is likely to continue into the prediction period and, if not, where prior information can most meaningfully be employed to produce structural estimates from which more useful forecasts can result.},
author = {Belsley, David A},
booktitle = {Journal of Forecasting},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Belsley - 1984 - Collinearity and Forecasting.pdf:pdf},
pages = {183--196},
title = {{Collinearity and Forecasting}},
volume = {3},
year = {1984}
}
@techreport{Zou2005,
abstract = {We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together. The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the p n case. An algorithm called LARS-EN is proposed for computing elastic net regularization paths efficiently, much like algorithm LARS does for the lasso.},
author = {Zou, Hui and Hastie, Trevor},
booktitle = {J. R. Statist. Soc. B},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Zou, Hastie - 2005 - Regularization and variable selection via the elastic net.pdf:pdf},
keywords = {Grouping effect,LARS algorithm,Lasso,Penalization,Variable selection,p n problem},
number = {2},
pages = {301--320},
title = {{Regularization and variable selection via the elastic net}},
volume = {67},
year = {2005}
}
@techreport{Schreiber-Gregory,
abstract = {Multicollinearity can be briefly described as the phenomenon in which two or more identified predictor variables in a multiple regression model are highly correlated. The presence of this phenomenon can have a negative impact on the analysis as a whole and can severely limit the conclusions of the research study. This paper reviews and provides examples of the different ways in which multicollinearity can affect a research project, and tells how to detect multicollinearity and how to reduce it once it is found. In order to demonstrate the effects of multicollinearity and how to combat it, this paper explores the proposed techniques by using the Youth Risk Behavior Surveillance System data set. This paper is intended for any level of SAS{\textregistered} user. This paper is also written to an audience with a background in behavioral science or statistics.},
author = {Schreiber-Gregory, Deanna N and {Jackson Foundation}, Henry M},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Schreiber-Gregory, Jackson Foundation - Unknown - Multicollinearity What Is It, Why Should We Care, and How Can It Be Controlled.pdf:pdf},
title = {{Multicollinearity: What Is It, Why Should We Care, and How Can It Be Controlled?}}
}
@article{Zhu2004,
abstract = {Classification of patient samples is an important aspect of cancer diagnosis and treatment. The support vector machine (SVM) has been successfully applied to microarray cancer diagnosis problems. However, one weakness of the SVM is that given a tumor sample, it only predicts a cancer class label but does not provide any estimate of the underlying probability. We propose penalized logistic regression (PLR) as an alternative to the SVM for the microarray cancer diagnosis problem. We show that when using the same set of genes, PLR and the SVM perform similarly in cancer classification, but PLR has the advantage of additionally providing an estimate of the underlying probability. Often a primary goal in microarray cancer diagnosis is to identify the genes responsible for the classification, rather than class prediction. We consider two gene selection methods in this paper, univariate ranking (UR) and recursive feature elimination (RFE). Empirical results indicate that PLR combined with RFE tends to select fewer genes than other methods and also performs well in both cross-validation and test samples. A fast algorithm for solving PLR is also described.},
author = {Zhu, Ji and Hastie, Trevor},
doi = {10.1093/biostatistics/kxg046},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Zhu, Hastie - 2004 - Classification of gene microarrays by penalized logistic regression.pdf:pdf},
issn = {14654644},
journal = {Biostatistics},
keywords = {Cancer diagnosis,Feature selection,Logistic regression,Microarray,Support vector machines},
month = {jul},
number = {3},
pages = {427--443},
title = {{Classification of gene microarrays by penalized logistic regression}},
volume = {5},
year = {2004}
}
@article{Saenger2002,
abstract = {Social status, as described by income and religion, largely determines a person's vote and other aspects of his political behavior. The voting trend in New York City over a long period appears to be a function of social status. Group membership is more important than party platforms or exposure to propaganda in determining the voter's choice. Where the voter's opinion conflicts with the established party line, the party program is interpreted in terms of the individual's own desires and beliefs. Those least aware of differences between the parties and least convinced that the outcome of the election will affect them personally are most likely to change parties.},
author = {Saenger, Gerhart H.},
doi = {10.1086/219742},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Saenger - 2002 - Social Status and Political Behavior.pdf:pdf},
issn = {0002-9602},
journal = {American Journal of Sociology},
month = {jul},
number = {2},
pages = {103--113},
publisher = {University of Chicago Press},
title = {{Social Status and Political Behavior}},
volume = {51},
year = {2002}
}
@techreport{Kwon2005,
author = {Kwon, Uisoon},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Kwon - 2005 - Who Voted Social Class and Participation in United States Presidential Elections.pdf:pdf},
title = {{Who Voted?: Social Class and Participation in United States Presidential Elections}},
url = {https://scholarworks.wmich.edu/dissertations},
year = {2005}
}
@techreport{Matera,
author = {Matera, Claudio},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Matera - Unknown - Comparing the influence of socioeconomic factors on participation in national elections and referendums.pdf:pdf},
title = {{Comparing the influence of socioeconomic factors on participation in national elections and referendums}}
}
@techreport{Ng,
abstract = {This set of notes presents the Support Vector Machine (SVM) learning algorithm. SVMs are among the best (and many believe are indeed the best) "off-the-shelf" supervised learning algorithms. To tell the SVM story, we'll need to first talk about margins and the idea of separating data with a large "gap." Next, we'll talk about the optimal margin classifier, which will lead us into a digression on Lagrange duality. We'll also see kernels, which give a way to apply SVMs efficiently in very high dimensional (such as infinite-dimensional) feature spaces, and finally, we'll close off the story with the SMO algorithm, which gives an efficient implementation of SVMs. 1 Margins: Intuition We'll start our story on SVMs by talking about margins. This section will give the intuitions about margins and about the "confidence" of our predictions ; these ideas will be made formal in Section 3. Consider logistic regression, where the probability p(y = 1|x; $\theta$) is mod-eled by h $\theta$ (x) = g($\theta$ T x). We would then predict "1" on an input x if and only if h $\theta$ (x) ≥ 0.5, or equivalently, if and only if $\theta$ T x ≥ 0. Consider a positive training example (y = 1). The larger $\theta$ T x is, the larger also is h $\theta$ (x) = p(y = 1|x; w, b), and thus also the higher our degree of "confidence" that the label is 1. Thus, informally we can think of our prediction as being a very confident one that y = 1 if $\theta$ T x ≫ 0. Similarly, we think of logistic regression as making a very confident prediction of y = 0, if $\theta$ T x ≪ 0. Given a training set, again informally it seems that we'd have found a good fit to the training data if we can find $\theta$ so that $\theta$ T x (i) ≫ 0 whenever y (i) = 1, and 1},
author = {Ng, Andrew},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Ng - Unknown - CS229 Lecture notes Support Vector Machines.pdf:pdf},
title = {{CS229 Lecture notes Support Vector Machines}}
}
@article{,
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - Why Voting Matters{\_}0.pdf:pdf},
title = {{Why Voting Matters{\_}0}}
}
@techreport{Nevitte2009,
abstract = {The user has requested enhancement of the downloaded file.},
author = {Nevitte, Neil and Blais, Andr{\'{e}} and Nadeau, Richard},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Nevitte, Blais, Nadeau - 2009 - Socioeconomic Status and Nonvoting A Cross-National Comparative Analysis.pdf:pdf},
title = {{Socioeconomic Status and Nonvoting: A Cross-National Comparative Analysis}},
url = {https://www.researchgate.net/publication/235319770},
year = {2009}
}
@incollection{Rosenbaum2016,
abstract = {This volume contains the papers presented at SocInfo 2012, the Fourth In- ternational Conference on Social Informatics, held on December 5–7, 2012 in Lausanne. SocInfo 2012 provided an interdisciplinary venue for researchers from com- puter science, informatics, social scie nces and management sciences to exchange ideas, opinions and original research work. After a year of hard work on the part of authors, reviewers and conference or ganizers, we were delighted to share with you a strong technical program at the conference. There were 69 submissions to the research track of SocInfo 2012, of which 21 full length presentation papers and 18 s hort presentation papers were accepted. Each submission was reviewed by at least 1, and on average 2.9, program com- mittee members. The acceptance decisi on was carefully made based on both reviews and online PC discussions. Our sincere thanks to all our colleagues who volunteered to serve as program committee members and reviewers on this year's program committee. We want to especia lly acknowledge the hard work of the PC Co-chair, Jie Tang, who took on the relentless task of driving the SocInfo 2012 review process to a conclusion. We are also extremely grateful to General Co-chairs Karl Aberer and Andreas Flache for their leadership, and to Surender Yerva from EPFL, who provided outstanding assistance and help to the program co-chairs with respect to the EasyChair system. We trust that you enjoyed this year's technical program and the unique op- portunity to exchange ideas and research results with researchers in computer science, informatics, social sciences and management sciences.},
author = {Rosenbaum, Howard},
booktitle = {Encyclopedia of Library and Information Sciences, Third Edition},
doi = {10.1081/e-elis3-120043526},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Rosenbaum - 2016 - Social Informatics.pdf:pdf},
month = {jul},
pages = {4814--4819},
publisher = {CRC Press},
title = {{Social Informatics}},
year = {2016}
}
@techreport{Sosnovski2018,
author = {Sosnovski, Bianca and Azrilyan, Elina and Mercier, Robert and Dvir-Djerassi, Asher and Joseph, Charls},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Sosnovski et al. - 2018 - Project 3 Executive Summary 1.1.1 Group Members.pdf:pdf},
title = {{Project 3 Executive Summary 1.1.1 Group Members}},
url = {https://rstudio-pubs-static.s3.amazonaws.com/431668{\_}94857a2237f24827b3fad12d6d9d851c.htmlurl:https://www.kaggle.com/benhamner/2016-us-election https://www.kaggle.com/benhamner/2016-us-election},
year = {2018}
}
@article{Katz1999,
abstract = {We propose a comprehensive statistical model for analyzing multiparty, district-level elections. This model, which provides a tool for comparative politics research analogous to that which regression analysis provides in the American two-party context, can be used to explain or predict how geographic distributions of electoral results depend upon economic conditions, neighborhood ethnic compositions, campaign spending, and other features of the election campaign or aggregate areas. We also provide new graphical representations for data exploration, model evaluation, and substantive interpretation. We illustrate the use of this model by attempting to resolve a controversy over the size of and trend in the electoral advantage of incumbency in Britain. Contrary to previous analyses, all based on measures now known to be biased, we demonstrate that the advantage is small but meaningful, varies substantially across the parties, and is not growing. Finally, we show how to estimate the party from which each party's advantage is predominantly drawn.},
author = {Katz, Jonathan N. and King, Gary},
doi = {10.2307/2585758},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Katz, King - 1999 - A Statistical Model for Multiparty Electoral Data.pdf:pdf},
issn = {0003-0554},
journal = {American Political Science Review},
month = {mar},
number = {1},
pages = {15--32},
publisher = {Cambridge University Press (CUP)},
title = {{A Statistical Model for Multiparty Electoral Data}},
volume = {93},
year = {1999}
}
@article{Goldsmiths,
author = {Goldsmiths, Caroline Butler},
doi = {10.13140/RG.2.2.31159.11681},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Goldsmiths - Unknown - Predicting Primary Elections with Mortality and Well-Being Data View project.pdf:pdf},
title = {{Predicting Primary Elections with Mortality and Well-Being Data View project}},
url = {https://www.researchgate.net/publication/308874305}
}
@techreport{Dubin1996,
author = {Dubin, Jeffrey A and Kalsow, Gretchen A},
booktitle = {Political Behavior},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Dubin, Kalsow - 1996 - COMPARING ABSENTEE AND PRECINCT VOTERS A View Over Time.pdf:pdf},
number = {4},
title = {{COMPARING ABSENTEE AND PRECINCT VOTERS: A View Over Time}},
volume = {18},
year = {1996}
}
@article{Brown2012,
abstract = {While it is too soon to predict the 2012 presidential winner, it is not too early to know that the general election is likely to be a fiercely competitive contest that will, assuming no major unexpected events occur (e.g., another recession), come down to a few thousand votes in a few swing states, most probably including Ohio. When a presidential election is this close, there exists the possibility that the popular vote winner and the electoral vote winner will differ, which has happened four times before (1824, 1876, 1888, and 2000), but continues to be controversial. More ominously, there is also a small, but real chance of an electoral vote tie between the candidates, which would then place the selection of the president in the House of Representatives and the vice president in the Senate. Even though congressional selection is the constitutionally prescribed remedy and has historical precedents (1800, 1824), it seems unlikely that the Electoral College would long survive what would surely be a spirited public debate over who should choose the president. Thus, the 2012 election results may be too close to sustain the legitimacy of the presidential selection method.},
author = {Brown, Lara M.},
doi = {10.1007/s12115-012-9576-2},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Brown - 2012 - How Close is Too Close The 2012 Election in the Electoral College.pdf:pdf},
issn = {01472011},
journal = {Society},
keywords = {Candidates,Closeness,Electoral college,Political parties,Presidential elections},
month = {sep},
number = {5},
pages = {418--422},
title = {{How Close is Too Close?: The 2012 Election in the Electoral College}},
volume = {49},
year = {2012}
}
@article{Furia2016,
abstract = {Statistics comes in two main flavors: frequentist and Bayesian. For historical and technical reasons, frequentist statistics has dominated data analysis in the past; but Bayesian statistics is making a comeback at the forefront of science. In this paper, we give a practical overview of Bayesian statistics and illustrate its main advantages over frequentist statistics for the kinds of analyses that are common in empirical software engineering, where frequentist statistics still is standard. We also apply Bayesian statistics to empirical data from previous research investigating agile vs. structured development processes, the performance of programming languages, and random testing of object-oriented programs. In addition to being case studies demonstrating how Bayesian analysis can be applied in practice, they provide insights beyond the results in the original publications (which used frequentist statistics), thus showing the practical value brought by Bayesian statistics.},
archivePrefix = {arXiv},
arxivId = {1608.06865},
author = {Furia, Carlo A.},
eprint = {1608.06865},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Furia - 2016 - Bayesian Statistics in Software Engineering Practical Guide and Case Studies.pdf:pdf},
month = {aug},
title = {{Bayesian Statistics in Software Engineering: Practical Guide and Case Studies}},
url = {http://arxiv.org/abs/1608.06865},
year = {2016}
}
@inproceedings{Mamykina2011,
abstract = {This paper analyzes a Question {\&} Answer site for programmers, Stack Overflow, that dramatically improves on the utility and performance of Q{\&}A systems for technical domains. Over 92{\%} of Stack Overflow questions about expert topics are answered - in a median time of 11 minutes. Using a mixed methods approach that combines statistical data analysis with user interviews, we seek to understand this success. We argue that it is not primarily due to an a priori superior technical design, but also to the high visibility and daily involvement of the design team within the community they serve. This model of continued community leadership presents challenges to both CSCW systems research as well as to attempts to apply the Stack Overflow model to other specialized knowledge domains.},
author = {Mamykina, Lena and Manoim, Bella and Mittal, Manas and Hripcsak, George and Hartmann, Bj{\"{o}}rn},
doi = {10.1145/1978942.1979366},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Mamykina et al. - 2011 - Design lessons from the fastest q{\&}a site in the west.pdf:pdf},
month = {may},
pages = {2857},
publisher = {Association for Computing Machinery (ACM)},
title = {{Design lessons from the fastest q{\&}a site in the west}},
year = {2011}
}
@article{Soares2018,
abstract = {This paper assesses the support vector regression (SVR) as a robust alternative to partial least squares (PLS) in multivariate calibration using twelve public domain NIR spectroscopy datasets. It also proposes the use of the support vector regression – recursive feature elimination (SVR-RFE) algorithm to select the most informative wavelengths for SVR models. Models based on full spectra were built using SVR and PLS, while wavelength selection methods were carried out using SVR-RFE, interval PLS (iPLS), backward interval PLS (biPLS), synergy interval PLS (siPLS), and successive projection algorithm PLS (SPA-PLS). The prediction performance of tested methods was measured by means of the root mean squared error (RMSE), index of agreement (d-index) and R2 on the test set. SVR-based models yielded the best results in 8 out of 12 datasets, 4 of them using full spectra and 4 relying on SVR-RFE selected wavelengths. Statistical comparison was carried out for the wavelength selection algorithms using Friedman test, which pointed the SVR-RFE as a competitive technique when compared to the other algorithms. This study revealed SVR as a robust alternative to PLS, especially when SVR-RFE is employed for wavelength selection.},
author = {Soares, Felipe and Anzanello, Michel J.},
doi = {10.1016/j.chemolab.2017.12.007},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Soares, Anzanello - 2018 - Support vector regression coupled with wavelength selection as a robust analytical method.pdf:pdf},
issn = {18733239},
journal = {Chemometrics and Intelligent Laboratory Systems},
keywords = {Partial least squares,Spectroscopy,Support vector regression,Support vector regression-recursive feature elimin,Wavelength selection},
month = {jan},
pages = {167--173},
publisher = {Elsevier B.V.},
title = {{Support vector regression coupled with wavelength selection as a robust analytical method}},
volume = {172},
year = {2018}
}
@article{Xiong2013,
abstract = {We propose a robust regression method called regression with outlier shrinkage (ROS) for the traditional n{\textgreater}. p cases. It improves over the other robust regression methods such as least trimmed squares (LTS) in the sense that it can achieve maximum breakdown value and full asymptotic efficiency simultaneously. Moreover, its computational complexity is no more than that of LTS. We also propose a sparse estimator, called sparse regression with outlier shrinkage (SROS), for robust variable selection and estimation. It is proven that SROS can not only give consistent selection but also estimate the nonzero coefficients with full asymptotic efficiency under the normal model. In addition, we introduce a concept of nearly regression equivariant estimator for understanding the breakdown properties of sparse estimators, and prove that SROS achieves the maximum breakdown value of nearly regression equivariant estimators. Numerical examples are presented to illustrate our methods. {\textcopyright} 2013 Elsevier B.V.},
author = {Xiong, Shifeng and Joseph, V. Roshan},
doi = {10.1016/j.jspi.2013.06.007},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Xiong, Joseph - 2013 - Regression with outlier shrinkage.pdf:pdf},
issn = {03783758},
journal = {Journal of Statistical Planning and Inference},
keywords = {Breakdown value,Penalized regression,Robust regression,Variable selection,Weighted least squares},
month = {nov},
number = {11},
pages = {1988--2001},
title = {{Regression with outlier shrinkage}},
volume = {143},
year = {2013}
}
@article{Saitta1995,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Saitta, Lorenza},
doi = {10.1007/BF00994018},
eprint = {arXiv:1011.1669v3},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Saitta - 1995 - Support-Vector Networks SVM.pdf.pdf:pdf},
isbn = {0885-6125},
issn = {08856125},
keywords = {efficient learning algorithms,neural networks,pattern recognition,polynomial classifiers,radial basis function classifiers},
pmid = {19549084},
title = {{Support-Vector Networks  SVM.pdf}},
year = {1995}
}
@techreport{Ganganwar2012,
abstract = {Unbalanced data set, a problem often found in real world application, can cause seriously negative effect on classification performance of machine learning algorithms. There have been many attempts at dealing with classification of unbalanced data sets. In this paper we present a brief review of existing solutions to the class-imbalance problem proposed both at the data and algorithmic levels. Even though a common practice to handle the problem of imbalanced data is to rebalance them artificially by oversampling and/or under-sampling, some researchers proved that modified support vector machine, rough set based minority class oriented rule learning methods, cost sensitive classifier perform good on imbalanced data set. We observed that current research in imbalance data problem is moving to hybrid algorithms.},
author = {Ganganwar, Vaishali},
booktitle = {International Journal of Emerging Technology and Advanced Engineering Website: www.ijetae.com},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Ganganwar - 2012 - An overview of classification algorithms for imbalanced datasets.pdf:pdf},
keywords = {cost-sensitive learning,imbalanced data set,modified SVM,oversampling,undersampling},
number = {4},
title = {{An overview of classification algorithms for imbalanced datasets}},
url = {www.ijetae.com},
volume = {2},
year = {2012}
}
@article{Hawkins2003,
author = {Hawkins, Douglas M and Basak, Subhash C and Mills, Denise},
doi = {10.1021/ci025626i},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Hawkins, Basak, Mills - 2003 - Assessing Model Fit by Cross-Validation.pdf:pdf},
pages = {55811},
publisher = {Miller Trunk Highway},
title = {{Assessing Model Fit by Cross-Validation}},
url = {https://pubs.acs.org/sharingguidelines},
volume = {5013},
year = {2003}
}
@techreport{Raschka2018,
abstract = {The correct use of model evaluation, model selection, and algorithm selection techniques is vital in academic machine learning research as well as in many industrial settings. This article reviews different techniques that can be used for each of these three subtasks and discusses the main advantages and disadvantages of each technique with references to theoretical and empirical studies. Further, recommendations are given to encourage best yet feasible practices in research and applications of machine learning. Common methods such as the holdout method for model evaluation and selection are covered, which are not recommended when working with small datasets. Different flavors of the bootstrap technique are introduced for estimating the uncertainty of performance estimates, as an alternative to confidence intervals via normal approximation if bootstrapping is computationally feasible. Common cross-validation techniques such as leave-one-out cross-validation and k-fold cross-validation are reviewed, the bias-variance trade-off for choosing k is discussed, and practical tips for the optimal choice of k are given based on empirical evidence. Different statistical tests for algorithm comparisons are presented, and strategies for dealing with multiple comparisons such as omnibus tests and multiple-comparison corrections are discussed. Finally, alternative methods for algorithm selection, such as the combined F-test 5x2 cross-validation and nested cross-validation, are recommended for comparing machine learning algorithms when datasets are small.},
archivePrefix = {arXiv},
arxivId = {1811.12808v2},
author = {Raschka, Sebastian},
eprint = {1811.12808v2},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Raschka - 2018 - Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning.pdf:pdf},
title = {{Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning}},
year = {2018}
}
@article{Austin2017,
abstract = {{\textcopyright} The Author(s) 2014. We conducted an extensive set of empirical analyses to examine the effect of the number of events per variable (EPV) on the relative performance of three different methods for assessing the predictive accuracy of a logistic regression model: apparent performance in the analysis sample, split-sample validation, and optimism correction using bootstrap methods. Using a single dataset of patients hospitalized with heart failure, we compared the estimates of discriminatory performance from these methods to those for a very large independent validation sample arising from the same population. As anticipated, the apparent performance was optimistically biased, with the degree of optimism diminishing as the number of events per variable increased. Differences between the bootstrap-corrected approach and the use of an independent validation sample were minimal once the number of events per variable was at least 20. Split-sample assessment resulted in too pessimistic and highly uncertain estimates of model performance. Apparent performance estimates had lower mean squared error compared to split-sample estimates, but the lowest mean squared error was obtained by bootstrap-corrected optimism estimates. For bias, variance, and mean squared error of the performance estimates, the penalty incurred by using split-sample validation was equivalent to reducing the sample size by a proportion equivalent to the proportion of the sample that was withheld for model validation. In conclusion, split-sample validation is inefficient and apparent performance is too optimistic for internal validation of regression-based prediction models. Modern validation methods, such as bootstrap-based optimism correction, are preferable. While these findings may be unsurprising to many statisticians, the results of the current study reinforce what should be considered good statistical practice in the development and validation of clinical prediction models.},
author = {Austin, Peter C. and Steyerberg, Ewout W.},
doi = {10.1177/0962280214558972},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Austin, Steyerberg - 2017 - Events per variable (EPV) and the relative performance of different strategies for estimating the out-of-sam.pdf:pdf},
issn = {14770334},
journal = {Statistical Methods in Medical Research},
keywords = {bootstrap,c-statistic,clinical prediction models,data splitting,discrimination,logistic regression,model validation,receiver operating characteristic curve},
month = {apr},
number = {2},
pages = {796--808},
publisher = {SAGE Publications Ltd},
title = {{Events per variable (EPV) and the relative performance of different strategies for estimating the out-of-sample validity of logistic regression models}},
volume = {26},
year = {2017}
}
@article{Dormann2013,
abstract = {Collinearity refers to the non independence of predictor variables, usually in a regression-type analysis. It is a common feature of any descriptive ecological data set and can be a problem for parameter estimation because it inflates the variance of regression parameters and hence potentially leads to the wrong identification of relevant predictors in a statistical model. Collinearity is a severe problem when a model is trained on data from one region or time, and predicted to another with a different or unknown structure of collinearity. To demonstrate the reach of the problem of collinearity in ecology, we show how relationships among predictors differ between biomes, change over spatial scales and through time. Across disciplines, different approaches to addressing collinearity problems have been developed, ranging from clustering of predictors, threshold-based pre-selection, through latent variable methods, to shrinkage and regularisation. Using simulated data with five predictor-response relationships of increasing complexity and eight levels of collinearity we compared ways to address collinearity with standard multiple regression and machine-learning approaches. We assessed the performance of each approach by testing its impact on prediction to new data. In the extreme, we tested whether the methods were able to identify the true underlying relationship in a training dataset with strong collinearity by evaluating its performance on a test dataset without any collinearity. We found that methods specifically designed for collinearity, such as latent variable methods and tree based models, did not outperform the traditional GLM and threshold-based pre-selection. Our results highlight the value of GLM in combination with penalised methods (particularly ridge) and threshold-based pre-selection when omitted variables are considered in the final interpretation. However, all approaches tested yielded degraded predictions under change in collinearity structure and the 'folk lore'-thresholds of correlation coefficients between predictor variables of |r| {\textgreater}0.7 was an appropriate indicator for when collinearity begins to severely distort model estimation and subsequent prediction. The use of ecological understanding of the system in pre-analysis variable selection and the choice of the least sensitive statistical approaches reduce the problems of collinearity, but cannot ultimately solve them. [ABSTRACT FROM AUTHOR]},
author = {Dormann, Carsten F. and Elith, Jane and Bacher, Sven and Buchmann, Carsten and Carl, Gudrun and Carr{\'{e}}, Gabriel and Marqu{\'{e}}z, Jaime R.Garc{\'{i}}a and Gruber, Bernd and Lafourcade, Bruno and Leit{\~{a}}o, Pedro J. and M{\"{u}}nkem{\"{u}}ller, Tamara and Mcclean, Colin and Osborne, Patrick E. and Reineking, Bj{\"{o}}rn and Schr{\"{o}}der, Boris and Skidmore, Andrew K. and Zurell, Damaris and Lautenbach, Sven},
doi = {10.1111/j.1600-0587.2012.07348.x},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Dormann et al. - 2013 - Collinearity A review of methods to deal with it and a simulation study evaluating their performance.pdf:pdf},
journal = {Ecography},
keywords = {collinearity},
mendeley-tags = {collinearity},
month = {jan},
number = {1},
pages = {027--046},
title = {{Collinearity: A review of methods to deal with it and a simulation study evaluating their performance}},
volume = {36},
year = {2013}
}
@article{Stoltzfus2011,
abstract = {Regression techniques are versatile in their application to medical research because they can measure associations, predict outcomes, and control for confounding variable effects. As one such technique, logistic regression is an efficient and powerful way to analyze the effect of a group of independent variables on a binary outcome by quantifying each independent variable's unique contribution. Using components of linear regression reflected in the logit scale, logistic regression iteratively identifies the strongest linear combination of variables with the greatest probability of detecting the observed outcome. Important considerations when conducting logistic regression include selecting independent variables, ensuring that relevant assumptions are met, and choosing an appropriate model building strategy. For independent variable selection, one should be guided by such factors as accepted theory, previous empirical investigations, clinical considerations, and univariate statistical analyses, with acknowledgement of potential confounding variables that should be accounted for. Basic assumptions that must be met for logistic regression include independence of errors, linearity in the logit for continuous variables, absence of multicollinearity, and lack of strongly influential outliers. Additionally, there should be an adequate number of events per independent variable to avoid an overfit model, with commonly recommended minimum "rules of thumb" ranging from 10 to 20 events per covariate. Regarding model building strategies, the three general types are direct/standard, sequential/hierarchical, and stepwise/statistical, with each having a different emphasis and purpose. Before reaching definitive conclusions from the results of any of these methods, one should formally quantify the model's internal validity (i.e., replicability within the same data set) and external validity (i.e., generalizability beyond the current sample). The resulting logistic regression model's overall fit to the sample data is assessed using various goodness-of-fit measures, with better fit characterized by a smaller difference between observed and model-predicted values. Use of diagnostic statistics is also recommended to further assess the adequacy of the model. Finally, results for independent variables are typically reported as odds ratios (ORs) with 95{\%} confidence intervals (CIs).},
author = {Stoltzfus, Jill C.},
doi = {10.1111/j.1553-2712.2011.01185.x},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Stoltzfus - 2011 - Logistic regression A brief primer.pdf:pdf},
issn = {10696563},
journal = {Academic Emergency Medicine},
month = {oct},
number = {10},
pages = {1099--1104},
title = {{Logistic regression: A brief primer}},
volume = {18},
year = {2011}
}
@techreport{Kotsiantis2007,
abstract = {Supervised machine learning is the search for algorithms that reason from externally supplied instances to produce general hypotheses, which then make predictions about future instances. In other words, the goal of supervised learning is to build a concise model of the distribution of class labels in terms of predictor features. The resulting classifier is then used to assign class labels to the testing instances where the values of the predictor features are known, but the value of the class label is unknown. This paper describes various supervised machine learning classification techniques. Of course, a single article cannot be a complete review of all supervised machine learning classification algorithms (also known induction classification algorithms), yet we hope that the references cited will cover the major theoretical issues, guiding the researcher in interesting research directions and suggesting possible bias combinations that have yet to be explored. Povzetek: Podan je pregled metod strojnega u{\v{c}}enja.},
author = {Kotsiantis, S B},
booktitle = {Informatica},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Kotsiantis - 2007 - Supervised Machine Learning A Review of Classification Techniques.pdf:pdf},
keywords = {classifiers,data mining techniques,intelligent data analysis,learning algorithms},
pages = {249--268},
title = {{Supervised Machine Learning: A Review of Classification Techniques}},
volume = {31},
year = {2007}
}
@article{Nikam2015,
abstract = {Classification is used to find out in which group each data instance is related within a given dataset. It is used for classifying data into different classes according to some constrains. Several major kinds of classification algorithms including C4.5, ID3, k-nearest neighbor classifier, Naive Bayes, SVM, and ANN are used for classification. Generally a classification technique follows three approaches Statistical, Machine Learning and Neural Network for classification. While considering these approaches this paper provides an inclusive survey of different classification algorithms and their features and limitations.},
author = {Nikam, Sagar S.},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Nikam - 2015 - A Comparative Study of Classification Techniques in Data Mining Algorithms.pdf:pdf},
journal = {A Comparative Study of Classification Techniques in Data Mining Algorithms},
keywords = {classification},
mendeley-tags = {classification},
number = {1},
pages = {13--19},
publisher = {Techno Research Publishers},
title = {{A Comparative Study of Classification Techniques in Data Mining Algorithms}},
url = {http://www.computerscijournal.org/vol8no1/a-comparative-study-of-classification-techniques-in-data-mining-algorithms/},
volume = {8},
year = {2015}
}
@article{N.vanWieringen2015,
abstract = {The linear regression model cannot be fitted to high-dimensional data, as the high-dimensionality brings about empirical non-identifiability. Penalized regression overcomes this non-identifiability by augmentation of the loss function by a penalty (i.e. a function of regression coefficients). The ridge penalty is the sum of squared regression coefficients, giving rise to ridge regression. Here many aspect of ridge regression are reviewed e.g. moments, mean squared error, its equivalence to constrained estimation, and its relation to Bayesian regression. Finally, its behaviour and use are illustrated in simulation and on omics data. Subsequently, ridge regression is generalized to allow for a more general penalty. The ridge penalization framework is then translated to logistic regression and its properties are shown to carry over. To contrast ridge penalized estimation, the final chapter introduces its lasso counterpart.},
archivePrefix = {arXiv},
arxivId = {1509.09169},
author = {{N. van Wieringen}, Wessel},
eprint = {1509.09169},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/N. van Wieringen - 2015 - Lecture notes on ridge regression.pdf:pdf},
month = {sep},
title = {{Lecture notes on ridge regression}},
url = {http://arxiv.org/abs/1509.09169},
year = {2015}
}
@article{Gelman2002,
abstract = {In an election, voting power - the probability that a single vote is decisive - is affected by the rule for aggregating votes into a single outcome. Voting power is important for studying political representation, fairness and strategy, and has been much discussed in political science. Although power indexes are often considered as mathematical definitions, they ultimately depend on statistical models of voting. Mathematical calculations of voting power usually have been performed under the model that votes are decided by coin flips. This simple model has interesting implications for weighted elections, two-stage elections (such as the U.S. Electoral College) and coalition structures. We discuss empirical failings of the coin-flip model of voting and consider, first, the implications for voting power and, second, ways in which votes could be modeled more realistically. Under the random voting model, the standard deviation of the average of n votes is proportional to 1/√n, but under more general models, this variance can have the form cn-$\alpha$ or √a - b log n. Voting power calculations under more realistic models present research challenges in modeling and computation.},
author = {Gelman, Andrew and Katz, Jonathan N. and Tuerlinckx, Francis},
doi = {10.1214/ss/1049993201},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Gelman, Katz, Tuerlinckx - 2002 - The mathematics and statistics of voting power.pdf:pdf},
journal = {Statistical Science},
number = {4},
pages = {420--435},
publisher = {Institute of Mathematical Statistics},
title = {{The mathematics and statistics of voting power}},
volume = {17},
year = {2002}
}
@techreport{Adkisson,
abstract = {This paper examines the 2016 Republican presidential primary vote for Donald Trump. Trump's primary campaign rhetoric emphasized the need to make America great again and proposed that he is the best candidate to make this happen. Counties with older, less educated, and economically stressed populations tended to give strong support to Trump in the primary suggesting that he is seen as something of a messiah candidate. Conclusions are based on the analysis of data from 2238 counties or county equivalents in the 35 states that held primary elections (rather than caucuses) and held both the Republican and Democratic primary on the same day. Results indicate that ideology, socio-demographics, and economic rationality were influential in the vote.},
annote = {Cannot be cited without permission},
author = {Adkisson, Richard V and Peach, James T},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Adkisson, Peach - Unknown - Save Us from Something! An Analysis of the 2016 U.S. Republican Presidential Primary Election.pdf:pdf},
title = {{Save Us from Something! An Analysis of the 2016 U.S. Republican Presidential Primary Election}}
}
@techreport{Stoffa2018,
abstract = {In this paper, it is proposed that voters, devoid of any pressing concerns that could be addressed at the federal level, will tend to vote by their ideology for their preferred party. However, given pressing concerns, they will vote for whichever party can address these concerns despite party affiliation. This hypothesis is extended to the county level by assuming counties can be defined as the aggregate of their voting residence and as such their behavior can be predicted by considering their past voting history, socioeconomic makeup, and party platform.},
author = {Stoffa, Joseph and Lisbona, Randall and Farrar, Christopher and Martos, Mike and Stoffa, Joseph ; and Lisbona, Randall ;},
booktitle = {SMU Data Science Review},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Stoffa et al. - 2018 - Predicting How U.S. Counties will Vote in Presidential Elections Through Analysis of Socio-Economic Factors, Voti.pdf:pdf},
number = {1},
title = {{Predicting How U.S. Counties will Vote in Presidential Elections Through Analysis of Socio-Economic Factors, Voting Heuristics, and Party Platforms}},
url = {https://scholar.smu.edu/datasciencereviewhttp://digitalrepository.smu.edu.Availableat:https://scholar.smu.edu/datasciencereview/vol1/iss1/4},
volume = {1},
year = {2018}
}
@article{,
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - pols{\_}w3245{\_}2009{\_}brown (2).pdf:pdf},
title = {pols{\_}w3245{\_}2009{\_}brown (3)}
}
@article{Shields2007,
abstract = {JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.},
author = {Shields, Todd G. and Goidel, Robert K.},
doi = {10.2307/2111783},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Shields, Goidel - 2007 - Participation Rates, Socioeconomic Class Biases, and Congressional Elections A Crossvalidation.pdf:pdf},
issn = {00925853},
journal = {American Journal of Political Science},
month = {mar},
number = {2},
pages = {683},
publisher = {JSTOR},
title = {{Participation Rates, Socioeconomic Class Biases, and Congressional Elections: A Crossvalidation}},
volume = {41},
year = {2007}
}
@article{Goldman2019,
abstract = {BACKGROUND The outcome of the 2016 presidential election is commonly attributed to socioeconomic and ethnic/racial issues, but health issues, including "deaths of despair," may also have contributed. OBJECTIVE To assess whether changes in age-adjusted death rates were independently associated with changes in presidential election voting in 2016 vs. 2008. DESIGN We used publicly available data in each of 3112 US counties to correlate changes in a county's presidential voting in 2016 compared with 2008 with recent changes in its age-adjusted death rate, after controlling for population and rural-urban status, median age, race/ethnicity, income, education, unemployment rate, and health insurance rate. DESIGN SETTING Cross-sectional analysis of county-specific data. SETTING/PARTICIPANTS All 3112 US counties. MAIN MEASURES The independent correlation of a county's change in age-adjusted death rate between 2000 and 2015 with its net percentage Republican gain or loss in the presidential election of 2016 vs. 2008. KEY RESULTS In 2016, President Trump increased the Republican presidential vote percentage in 83.8{\%} of counties compared with Senator McCain in 2008. Counties with an increased Republican vote percentage in 2016 vs. 2008 had a 15{\%} higher 2015 age-adjusted death rate than counties with an increased Democratic vote percentage. Since 2000, overall death rates declined by less than half as much, and death rates from drugs, alcohol, and suicide increased 2.5 times as much in counties with Republican gains compared with counties with Democratic gains. In multivariable analyses, Republican net presidential gain in 2016 vs. 2008 was independently correlated with slower reductions in a county's age-adjusted death rate. Although correlation cannot infer causality, modest reductions in death rates might theoretically have shifted Pennsylvania, Michigan, and Wisconsin to Secretary Clinton. CONCLUSIONS Less of a reduction in age-adjusted death rates was an independent correlate of an increased Republican percentage vote in 2016 vs. 2008. Death rates may be markers of dissatisfactions and fears that influenced the 2016 Presidential election outcomes.},
author = {Goldman, Lee and Lim, Maribel P. and Chen, Qixuan and Jin, Peng and Muennig, Peter and Vagelos, Andrew},
doi = {10.1007/s11606-018-4568-6},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Goldman et al. - 2019 - Independent Relationship of Changes in Death Rates with Changes in US Presidential Voting.pdf:pdf},
issn = {15251497},
journal = {Journal of General Internal Medicine},
keywords = {2016 election,age-adjusted death rate,deaths of despair,presidential election,rural public health},
month = {mar},
number = {3},
pages = {363--371},
publisher = {Springer New York LLC},
title = {{Independent Relationship of Changes in Death Rates with Changes in US Presidential Voting}},
volume = {34},
year = {2019}
}
@phdthesis{Jansen2017,
abstract = {This  thesis  concerns  an  empirical  comparison  between  dierential  evolution  and gradient-based optimisation methods, applied to articial neural network training. The gradient-based methods outperform dierential evolution.  A logistic regression model is considered.  The results, however, suggest that a more elaborate network architecture is required to grasp the non-linearities in the data to the fullest extent.},
author = {Jansen, Lennert},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Jansen - 2017 - Retrospective Forecasts of the 2016 U.S. Primary Elections.pdf:pdf},
school = {University of Amsterdam},
title = {{Retrospective Forecasts of the 2016 U.S. Primary Elections}},
year = {2017}
}
@techreport{,
abstract = {The 2016 US Presidential Election was unprecedented, as traditional prediction methods failed to forecast the outcome. Using a demographic and political opinion survey of confirmed voters, we characterized President Trump's voters, particularly "non-Republicans," with two hypotheses: 1) Trump voters were economically downtrodden and 2) voters aligned with Trump's immigration and race rhetoric. We created two multilevel models with voter and state level variables and found partial support for the "economically downtrodden" hypothesis: a belief the economy became worse under President Obama was a strong predictor of a non-Republican vote for Trump. Actual income was not a significant predictor of vote. We also found support for the "race politics" hypothesis: supporting policies to curb immigration was a meaningful predictor non-Republicans would vote for Trump. While Republicans largely followed party lines, swing voters expressed discontent with the status of current economic and immigration/race issues and propelled Trump to the White House. Introduction In the 2016 presidential election, polls and predictive models failed to predict Donald Trump's victory. Since the election, many hypotheses have circulated as to why Trump received many unexpected votes. We set out to study the driving forces behind Trump's win by evaluating common characteristics among his voters. We evaluated two working hypotheses among political scientists using multi-level statistical modeling. The first hypothesis studied is that Trump voters tended to be economically downtrodden, voting for Trump as a candidate of change because of personal economic hardships. While this hypothesis finds support in popular media, there is evidence in opposition to it. 1 The second hypothesis is that Trump exploited fear of minorities and immigrants, therefore Trump voters' thoughts tend to parallel this rhetoric. Previous studies identified fear of losing majority status indeed impacts voting choice. 2 In addition, we assess how Trump's social rhetoric affected religiously-motivated voting, since his campaign emphasized retaliating against increasing secularization of the political landscape. Political scientists disagree on the causes of Trump's unexpected victory, but the hypotheses we evaluate relate to some of the most popular working theories attempting to explain the 2016 presidential election outcome.},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - Understanding the 2016 Presidential Election An analysis of how economic and raceimmigration politics influenced swi.pdf:pdf},
title = {{Understanding the 2016 Presidential Election: An analysis of how economic and race/immigration politics influenced swing voters}}
}
@article{,
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - 2019{\_}Book{\_}PoliticsProtestAndYoungPeople.pdf:pdf},
title = {{2019{\_}Book{\_}PoliticsProtestAndYoungPeople}}
}
@article{Kurnaz2018,
abstract = {Fully robust versions of the elastic net estimator are introduced for linear and logistic regression. The algorithms used to compute the estimators are based on the idea of repeatedly applying the non-robust classical estimators to data subsets only. It is shown how outlier-free subsets can be identified efficiently, and how appropriate tuning parameters for the elastic net penalties can be selected. A final reweighting step improves the efficiency of the estimators. Simulation studies compare with non-robust and other competing robust estimators and reveal the superiority of the newly proposed methods. This is also supported by a reasonable computation time and by good performance in real data examples.},
author = {Kurnaz, Fatma Sevin{\c{c}} and Hoffmann, Irene and Filzmoser, Peter},
doi = {10.1016/j.chemolab.2017.11.017},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Kurnaz, Hoffmann, Filzmoser - 2018 - Robust and sparse estimation methods for high-dimensional linear and logistic regression.pdf:pdf},
issn = {18733239},
journal = {Chemometrics and Intelligent Laboratory Systems},
keywords = {C-step algorithm,Elastic net penalty,High-dimensional data,Least trimmed squares,Robustness,Sparse estimation},
month = {jan},
pages = {211--222},
publisher = {Elsevier B.V.},
title = {{Robust and sparse estimation methods for high-dimensional linear and logistic regression}},
volume = {172},
year = {2018}
}
@inproceedings{Wang2008,
abstract = {Learning from data is one of the basic ways humans perceive the world and acquire the knowledge. Support vector machine (SVM for short) has emerged as a good classification technique and achieved excellent generalization performance in a variety of applications. Training SVM on a dataset of huge size with millions of data is a challenging problem since it is computationally expensive and the memory requirement grows with the square of the number of training examples. This paper surveys SVM training algorithms and falls them into three groups. Moreover, recent advances such as finite Newton method and active learning algorithms are described.},
author = {Wang, Guosheng},
booktitle = {Proceedings - 4th International Conference on Networked Computing and Advanced Information Management, NCM 2008},
doi = {10.1109/NCM.2008.103},
file = {:Users/mayrop/Library/Application Support/Mendeley Desktop/Downloaded/Wang - 2008 - A survey on training algorithms for support vector machine classifiers.pdf:pdf},
isbn = {9780769533223},
title = {{A survey on training algorithms for support vector machine classifiers}},
year = {2008}
}
